{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\15163\\.conda\\envs\\FDH\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # keras = 2.15.0\n",
    "import pandas as pd # 2.1.3\n",
    "import numpy as np # 1.26.2\n",
    "import matplotlib.pyplot as plt # 3.8.2\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler # 1.3.2\n",
    "import ast # python = 3.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime2index(data,time_clo):\n",
    "    # Converts dates to a 'datetime' class and sets it as an index\n",
    "    data[time_clo] = pd.to_datetime(data[time_clo])\n",
    "    data.set_index(time_clo, inplace=True)\n",
    "    try:\n",
    "        data = data.drop(\"Unnamed: 0\",axis=1) # drop unnamed column\n",
    "    except:\n",
    "        return data\n",
    "    return data\n",
    "\n",
    "# load datas\n",
    "data = pd.read_csv('./datas.csv')\n",
    "# Load labels\n",
    "monthly_labels = pd.read_csv(\"./monthly_merged_label.csv\")\n",
    "quarterly_labels = pd.read_csv(\"./Quarterly_merged_label.csv\")\n",
    "\n",
    "# Converts dates to a 'datetime' class and sets it as an index\n",
    "data = datetime2index(data,'times')\n",
    "# two kinds of labels\n",
    "monthly_labels = datetime2index(monthly_labels,'observation_date')\n",
    "quarterly_labels = datetime2index(quarterly_labels,'observation_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of data: 2569 \n",
      "missing values:\n",
      " sentiment_scores_1          651\n",
      "sentiment_scores_2          651\n",
      "sentiment_scores_3          651\n",
      "sentiment_scores_4          651\n",
      "sentiment_scores_1_mean    1226\n",
      "sentiment_scores_1_std     1226\n",
      "sentiment_scores_2_mean     674\n",
      "sentiment_scores_2_std      674\n",
      "sentiment_scores_3_mean     674\n",
      "sentiment_scores_3_std      674\n",
      "sentiment_scores_4_mean    1387\n",
      "sentiment_scores_4_std     1387\n",
      "dtype: int64\n",
      "Index(['sentiment_scores_1_mean', 'sentiment_scores_1_std',\n",
      "       'sentiment_scores_2_mean', 'sentiment_scores_2_std',\n",
      "       'sentiment_scores_3_mean', 'sentiment_scores_3_std',\n",
      "       'sentiment_scores_4_mean', 'sentiment_scores_4_std'],\n",
      "      dtype='object')\n",
      "(85, 31, 8)\n"
     ]
    }
   ],
   "source": [
    "# Completion of missing dates\n",
    "# 1. Create a DataFrame with all the dates.\n",
    "all_dates = pd.date_range(start=data.index.min(), end=data.index.max(), freq='D')\n",
    "all_dates_df = pd.DataFrame(index=all_dates)\n",
    "\n",
    "# 2. Merging data\n",
    "data = all_dates_df.join(data, how='left')\n",
    "missing_values_per_column = data.isna().sum()\n",
    "print('len of data:',len(data),'\\nmissing values:\\n',missing_values_per_column)\n",
    "# Completion of statistics for missing dates with 0\n",
    "data = data.fillna(0)\n",
    "# the input feature columns\n",
    "print(data.columns[4:])\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Prepare the inputs\n",
    "input_data = []\n",
    "for month, group in data.groupby(pd.Grouper(freq='M')): # M：Month；Q：Quarter\n",
    "    # monthly_feature = group[['mean', 'median', 'max', 'min', 'std', 'rolling_mean', 'rolling_std', 'change_rate']].values\n",
    "    monthly_feature = group[data.columns[4:]].values\n",
    "    input_data.append(monthly_feature)\n",
    "\n",
    "# Use pad_sequences for padding to ensure that the data is the same length for each month/quarter\n",
    "input_data_padded = pad_sequences(input_data, padding='post', dtype='float32')\n",
    "# Checking the shape of the filled data\n",
    "print(input_data_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-10-20 00:00:00 2013-11-30 00:00:00 2013-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.offsets import MonthEnd\n",
    "from pandas.tseries.offsets import QuarterEnd\n",
    "#  确定时间范围\n",
    "start_date = data.index.min() # 开始时间\n",
    "month_end_date = data.index.max()  + MonthEnd(1) # 用过去预测未来\n",
    "quarter_end_date = data.index.max()  + QuarterEnd(1)\n",
    "print(start_date,month_end_date,quarter_end_date)\n",
    "# 筛选对应时间范围内的标签\n",
    "monthly_labels = monthly_labels.loc[start_date:month_end_date]\n",
    "quarterly_labels = quarterly_labels.loc[start_date:quarter_end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 1)\n"
     ]
    }
   ],
   "source": [
    "# Initialising a MinMaxScater\n",
    "scaler = MinMaxScaler()\n",
    "# select the predicted label\n",
    "'''\n",
    "在这里选择要预测的标签\n",
    "'''\n",
    "label = monthly_labels['CMRMT'] # 85\n",
    "# label = quarterly_labels['GDP Growth Rate'] # 28 # GDP index\n",
    "label_scaled = scaler.fit_transform(label.values.reshape(-1, 1))\n",
    "# label_scaled = label.values.reshape(-1,1)\n",
    "print(label_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 31, 8) (17, 31, 8)\n",
      "(68, 1) (17, 1)\n"
     ]
    }
   ],
   "source": [
    "# The datas and labels for model training\n",
    "X = input_data_padded # for monthly labels\n",
    "# X = input_data_padded[:28] # for quarterly labels : 缺少一个最新季度的标签所以不得不去掉最后一个月的特征\n",
    "y = label_scaled\n",
    "\n",
    "# 留出验证，划分训练集和测试集\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型进行预测:\n",
    "import tensorflow as tf\n",
    "# 指定保存模型的路径\n",
    "model_path = './models/***.h5'\n",
    "# 加载模型\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "# 查看模型的结构\n",
    "loaded_model.summary()\n",
    "# 使用加载的模型进行预测\n",
    "# loaded_model.predict(X/X_train/X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FDH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
